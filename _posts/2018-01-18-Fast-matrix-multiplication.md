---
layout: post
title: "행렬 연산 최적화 기록"
date: 2018-01-18 00:00:25 +0900
description: 행렬 연산을 빠르게 만들면서 배운 점들
img: # None
---

# Matrix multiplication

행렬 연산이란 기본적으로 다음과 같다. (행렬에 대한 정의는 넘어가도록 함)
$$
r_{ij} = \sum_ka_{ik}b_{kj}
$$
$$N^2$$ 크기의 행렬이라고 했을 때, 가장 Naive한 알고리즘은 $$N^3$$ 의 시간을 소요한다.

## More efficient algorithm

### Strassen algorithm

$$
C=A*B\\
A=\left[ {\begin{array}{cc}
	A_{1,1} & A_{1,2} \\
	A_{2,1} & A_{2,2} \\
\end{array}} \right]
B=\left[ {\begin{array}{cc}
	B_{1,1} & B_{1,2} \\
	B_{2,1} & B_{2,2} \\
\end{array}} \right]
C=\left[ {\begin{array}{cc}
	C_{1,1} & C_{1,2} \\
	C_{2,1} & C_{2,2} \\
\end{array}} \right]
$$

이면은
$$
C_{1,1} = A_{1,1}B_{1,1} + A_{1,2}B_{2,1}\\
C_{1,2} = A_{1,1}B_{1,2} + A_{1,2}B_{2,2}\\
C_{2,1} = A_{2,1}B_{1,1} + A_{2,2}B_{2,1}\\
C_{2,2} = A_{2,1}B_{1,2} + A_{2,2}B_{2,2}\\
$$
일 것이다. 이 때 만약
$$
M_1 := (A_{1,1} + A_{2,2})(B_{1,1} + B_{2,2})\\
M_2 := (A_{2,1} + A_{2,2})B_{1,1}\\
M_3 := A_{1,1}(B_{1,2} - B_{2,2})\\
M_4 := A_{2,2}(B_{2,1} - B_{1,1})\\
M_5 := (A_{1,1}+A_{1,2})B_{2,2}\\
M_6 := (A_{2,1}+A_{1,1})(B_{1,1}+B_{1,2})\\
M_7 := (A_{1,2}-A_{2,2})(B_{2,1}+B_{2,2})\\
$$
이라면
$$
C_{1,1} = M_1 + M_4 - M_5 + M_7\\
C_{1,2} = M_3 + M_5\\
C_{2,1} = M_2 + M_4\\
C_{2,2} = M_1 - M_2 + M_3 + M_6
$$
인 것을 알 수 있다.

이 과정을 재귀적으로 반복해서 행렬을 계산했을 경우에 총 $$7*n^{\log_27}-6*n^2$$ 번의 연산이 필요하다. $$log_27 = 2.807...$$ 이기 때문에 시간이 약 $$O(n^{2.807})$$ 걸리는 것을 알 수 있다.

[구현](https://github.com/smilu97/system-hyu/tree/master/matrix_strassen)

## Optimizing cache

Naive algorithm에서 행렬을 계산할 때, 행을 바꿔가면서 원소에 접근하는 일이 발생하게 된다. 그런데 보통 행렬이 저장될 때에는 같은 행에 있는 원소들끼리 물리적으로 가까이 위치하게 된다. 그렇기 때문에 행을 바꿔가면서 접근하게 되면 공간 지역성이 떨어지게 되기 때문에, 전치행렬을 미리 하나 만들어두고 전치행렬을 가지고 접근하게 되면 캐시미스율이 향상되면서 속도가 14배 정도 향상되게 된다.

## GPGPU

행렬연산은 꽤 많은 곳에서 사용되기 때문에 요즈음 대부분의 머신에는 GPU에서 행렬을 계산하는데, GPU는 작고 많은 연산을 병렬로 수행하는 데에 특화되어 있기 때문에 CPU만 사용하는 것에 비해 더 좋은 성능을 낼 수 있다.

CUDA라이브러리를 사용해서 GPGPU를 수행해보면 약 140배 정도 속도가 향상되는 것을 볼 수 있다.

[구현](https://github.com/smilu97/system-hyu/tree/master/matrix_cuda)